{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intake the training data and only keep the necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Sentiment\n",
       "0  im getting on borderlands and i will murder yo...  Positive\n",
       "1  I am coming to the borders and I will kill you...  Positive\n",
       "2  im getting on borderlands and i will kill you ...  Positive\n",
       "3  im coming on borderlands and i will murder you...  Positive\n",
       "4  im getting on borderlands 2 and i will murder ...  Positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Twitter_training.csv', names=[\"Tweet_ID\", \"Entity\", \"Sentiment\", \"Text\"])\n",
    "data = data[['Text','Sentiment']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to identify Positive and Negative tweets, drop everything else and keep only valid text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data = data[data.Sentiment != \"Neutral\"]\n",
    "data = data[data.Sentiment != \"Irrelevant\"]\n",
    "data.Text = data.Text.apply(lambda x: str(x).lower())\n",
    "data.Text = data.Text.apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatize words to elimate stopwords that provide no context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\savio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\savio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\savio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words())\n",
    "def remove_stopwords(ls):\n",
    "    # Removes stop words and lemmatises\n",
    "    ls = [lemmatiser.lemmatize(word) for word in ls if word not in (stopwords) and (word.isalpha())]\n",
    "    \n",
    "    ls = \" \".join(ls)\n",
    "    return ls\n",
    "\n",
    "data.Text = data.Text.apply(word_tokenize)\n",
    "data.Text = data.Text.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the words to eliminate variations of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41664\n",
      "45084\n"
     ]
    }
   ],
   "source": [
    "print(data[data.Sentiment == 'Positive'].size)\n",
    "print(data[data.Sentiment == 'Negative'].size)\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_features = 1000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data.Text.values)\n",
    "X = tokenizer.texts_to_sequences(data.Text.values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of data after applying transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>getting borderland murder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coming border kill</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>getting borderland kill</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coming borderland murder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>getting borderland murder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Text Sentiment\n",
       "0  getting borderland murder  Positive\n",
       "1         coming border kill  Positive\n",
       "2    getting borderland kill  Positive\n",
       "3   coming borderland murder  Positive\n",
       "4  getting borderland murder  Positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we used LSTM, a recurrent neural network implmentation, to differentiate and distinguish the context of the content as the method to determining sentiment. \n",
    "\n",
    "The LSTM layer only uses the dropout and not the recurrent_dropout parameter in order to accelerate training. Recurrent_dropout is currently not supported by Nvidia CUDNN and will prevent the model from utilizing GPU acceleration.\n",
    "\n",
    "The Dense layer should only be 2 units as our sentiment has only 2 possible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 99, 128)           128000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 99, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 383,194\n",
      "Trainable params: 383,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential([\n",
    "     Embedding(max_features, embed_dim, input_length = X.shape[1]),\n",
    "     SpatialDropout1D(0.4),\n",
    "     LSTM(lstm_out, dropout=0.2),\n",
    "     Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "     loss='categorical_crossentropy',\n",
    "     optimizer='adam',\n",
    "     metrics=['accuracy']\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29060, 99) (29060, 2)\n",
      "(14314, 99) (14314, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data.Sentiment).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "909/909 [==============================] - 13s 12ms/step - loss: 0.4606 - accuracy: 0.7762\n",
      "Epoch 2/10\n",
      "909/909 [==============================] - 11s 12ms/step - loss: 0.3793 - accuracy: 0.8256\n",
      "Epoch 3/10\n",
      "909/909 [==============================] - 11s 12ms/step - loss: 0.3457 - accuracy: 0.8419\n",
      "Epoch 4/10\n",
      "909/909 [==============================] - 11s 12ms/step - loss: 0.3169 - accuracy: 0.8549\n",
      "Epoch 5/10\n",
      "909/909 [==============================] - 11s 12ms/step - loss: 0.2946 - accuracy: 0.8656\n",
      "Epoch 6/10\n",
      "909/909 [==============================] - 11s 12ms/step - loss: 0.2721 - accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "909/909 [==============================] - 11s 13ms/step - loss: 0.2538 - accuracy: 0.8829\n",
      "Epoch 8/10\n",
      "909/909 [==============================] - 11s 12ms/step - loss: 0.2355 - accuracy: 0.8898\n",
      "Epoch 9/10\n",
      "909/909 [==============================] - 11s 12ms/step - loss: 0.2220 - accuracy: 0.8978\n",
      "Epoch 10/10\n",
      "909/909 [==============================] - 12s 13ms/step - loss: 0.2080 - accuracy: 0.9047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19cb316d160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 10, batch_size=32,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=4)], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 - 2s - loss: 0.3184 - accuracy: 0.8707\n",
      "score: 0.32\n",
      "acc: 0.87\n"
     ]
    }
   ],
   "source": [
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = 32)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tests on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_acc 90.19337016574586 %\n",
      "neg_acc 84.27835051546391 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = {\n",
    "    'pos_cnt':0, \n",
    "    'neg_cnt':0, \n",
    "    'pos_correct':0, \n",
    "    'neg_correct':0\n",
    "}\n",
    "\n",
    "def inc(count):\n",
    "    count+=1\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]), batch_size=1)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        accuracy['neg_correct' if np.argmax(Y_validate[x]) == 0 else 'pos_correct'] +=1\n",
    "       \n",
    "    accuracy['neg_cnt' if np.argmax(Y_validate[x]) == 0 else 'pos_cnt'] +=1\n",
    "\n",
    "print(\"pos_acc\", accuracy['pos_correct']/accuracy['pos_cnt']*100, \"%\")\n",
    "print(\"neg_acc\", accuracy['neg_correct']/accuracy['neg_cnt']*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the tweet by the pre-fitted tokenizer instance then pad the tweet to have the same dimensions as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0  10 308 167 902]]\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 99) for input KerasTensor(type_spec=TensorSpec(shape=(None, 99), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (1, 28).\n",
      "1/1 - 0s\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "def apply_prediction(twt):\n",
    "    twtData = tokenizer.texts_to_sequences([twt])\n",
    "    twtData = pad_sequences(twtData, maxlen=28, dtype='int32', value=0)\n",
    "    print(twtData)\n",
    "    sentiment = model.predict(twtData,batch_size=1,verbose = 2)[0]\n",
    "    sentimentValue = \"negative\" if(np.argmax(sentiment) == 0) else \"positive\"\n",
    "    return sentimentValue\n",
    "    \n",
    "twt = 'The new CoD is pretty lit'\n",
    "print(apply_prediction(twt))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e4631f8abf22b6e3bad75ef6fc74e8156bc6d7eda16a6da5468122f1c7f4a75"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
